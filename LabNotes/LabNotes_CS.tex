\documentclass[pra,11 pt]{revtex4-1}

\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{amsmath,mathrsfs}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{grffile}
\usepackage{hyperref}
\title{Lab Notes for Compressed Sensing Coding}


\newcommand{\me}{\mathrm{e}}
\newcommand{\ep}{\varepsilon}
\newcommand{\sectionbreak}{\clearpage\newpage}
\newcommand{\mitem}{\item[--]}
\newcommand{\bo}{\noindent\textbf}
\newcommand{\etal}{\emph{et. al.}}

\usepackage[nodisplayskipstretch]{setspace}
\usepackage{fancyhdr}
\pagestyle{fancy}

\fancyhead[R]{Salerno}
\fancyhead[C]{Lab Notes for Compressed Sensing Coding}
\fancyhead[L]{MICe}

\begin{document}

\vfill

  \begin{titlepage}
    \vspace*{\fill}
    \begin{center}
      {\huge {Lab Notes for Compressed Sensing Coding}}\\[0.5cm]
      {\large {Anthony Salerno}}\\[0.4cm]
      \today
    \end{center}
    \vspace*{\fill}
  \end{titlepage}

\clearpage
\newpage

\noindent \emph{02.17.15 - 02.18.15}

\bo{Introduction}\\
Beginning work on the ``Proof of Principle" as per the 12.19.14 Meeting Notes - Plan 2

The notes state that we are to:
\begin{itemize}
  \item Pick one slice - extract slice from dataset with FT on RO (i.e. in dim space) and no FT on PE1 and PE2 (aka PE and SL)
  \item Isotropic undersampling (I think this is a bad idea)
  \item Recon slices independently with Lustig code (using $\lambda_2 psi[m] + \lambda_1 TV[m]$)
  \item Add a directional similarity term to the recon (so we can recon similar slices simulataneously) ($\lambda_3 ||m_j - m_k||_2 f(\vec{d_j} \cdot \vec{d_k}))$
  \item However, the form of $f((\vec{d_j}\cdot \vec{d_k}))$ is still unknown
\end{itemize}

\noindent Note that the git repository for this work can be found at \url{https://github.com/aasalerno/Lustig}.


\bo{Hypothesis}\\
To begin, today we should be able to get a decent code running that can do Lustig's code on any specified slice that we choose. I expect that the code will work as expected and provide a good rendition of the undersampled data with minimal alterations required. The hope is that we can use the basis of the code as an engine (that will need some optimization) in order to work with the data as we so hope.


\bo{Notes - Unpolished}\\
First spent a ridiculous amount of time getting \LaTeX up and running on this computer... But it works now! 

The code is written both on my computer as well as on the lab computers -- via a central git on github -- using the same datasets as required. The datasets in use are Jacob's data, reconstructed purely using the standard recon algorithm (that is, no MATLAB involved).

For all pushes and pulls, see the github repository. There are many (and it can be mapped by day!)

The code is to be written such that it is built and any values that are above 1-sampFac will be included. This means that when we are actually tacking on the $r$ correction, we need to do it as $1-\frac{r}{\text{max}(r)}$

Seem to have a problem with the values that I'm getting. The outer portions of k-space seem to have almost no chance of being chosen. With a penalty threshold of only 0.25 (given a sampFac of 0.5), only 40\% of values are chosen. Most of the lost points are on the corners of $k$-space, so this may be ok... However, I need to look into \textbf{possibly making the CS type sequence specific, for things like cylindrical acquisition}.

As of about 11:00 (commit 6a9cfb111c508df0af9a7222ba277ef118ba147), the code \texttt{testMap.m} is up and running. It will be used in order to actually build the map of what we are undersampling and then this will be pumped into an adapted version of Lustig's code in order to get it up and running.

Encountered a bit of an issue with how the data is obtained. Since this information is only the magnitude of the data, I'm going to make a version that can handle taking the real and imaginary parts of the data, then feeding that through to the next set of functions.

As of 12:08 PM, functionality has been added for the function to handle two files containing the real and imaginary parts of the $k$-space information!

Now, we want to add in the CS part of the code. Here is where things become a little painful, but we can look at the datasets and actually do what is done in CS.

For some unapparent reason, the code doesn't seem to want to work. This is really annoying and irritating as the error seems to be stemming from the raw files, which may render a tonne of previous work that I've done utterly useless. Ok, scratch that -- the issue was my method of plotting. I wasn't plotting the abs of the data. 

As of about 5:00 it is working. I'm going to git push it and go home.
\end{document}